<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>MLJ Cheatsheet · MLJ</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLJ</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><a class="toctext" href="../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="toctext" href="../model_search/">Model Search</a></li><li><a class="toctext" href="../machines/">Machines</a></li><li><a class="toctext" href="../evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="toctext" href="../performance_measures/">Performance Measures</a></li><li><a class="toctext" href="../tuning_models/">Tuning Models</a></li><li><a class="toctext" href="../learning_curves/">Learning Curves</a></li><li><a class="toctext" href="../built_in_transformers/">Built-in Transformers</a></li><li><a class="toctext" href="../composing_models/">Composing Models</a></li><li><a class="toctext" href="../homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="toctext" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="toctext" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="toctext" href="../benchmarking/">Benchmarking</a></li><li><a class="toctext" href="../working_with_tasks/">Working with Tasks</a></li><li><a class="toctext" href="../internals/">Internals</a></li><li><a class="toctext" href="../glossary/">Glossary</a></li><li><a class="toctext" href="../api/">API</a></li><li class="current"><a class="toctext" href>MLJ Cheatsheet</a><ul class="internal"></ul></li><li><a class="toctext" href="../NEWS/">MLJ News</a></li><li><a class="toctext" href="../frequently_asked_questions/">FAQ</a></li><li><a class="toctext" href="../julia_blogpost/">Julia BlogPost</a></li><li><a class="toctext" href="../acceleration_and_parallelism/">Acceleration and Parallelism</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>MLJ Cheatsheet</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/mlj_cheatsheet.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>MLJ Cheatsheet</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="MLJ-Cheatsheet-1" href="#MLJ-Cheatsheet-1">MLJ Cheatsheet</a></h1><h4><a class="nav-anchor" id="Starting-an-interactive-MLJ-session-1" href="#Starting-an-interactive-MLJ-session-1">Starting an interactive MLJ session</a></h4><pre><code class="language-julia-repl">julia&gt; using MLJ

julia&gt; MLJ_VERSION # version of MLJ for this cheatsheet
&quot;0.7.0&quot;</code></pre><h4><a class="nav-anchor" id="Model-search-and-code-loading-1" href="#Model-search-and-code-loading-1">Model search and code loading</a></h4><p><code>info(&quot;PCA&quot;)</code> retrieves registry metadata for the model called &quot;PCA&quot;</p><p><code>info(&quot;RidgeRegressor&quot;, pkg=&quot;MultivariateStats&quot;)</code> retrieves metadata for &quot;RidgeRegresssor&quot;, which is provided by multiple packages</p><p><code>models()</code> lists metadata of every registered model.</p><p><code>models(x -&gt; x.is_supervised &amp;&amp; x.is_pure_julia)</code> lists all supervised models written in pure julia.</p><p><strong>experimental:</strong> <code>models(matching(X))</code> lists all unsupervised models compatible with input <code>X</code>.</p><p><strong>experimental!</strong> <code>models(matching(X, y))</code> lists all supervised modesl compatible with input/target <code>X/y</code>.</p><p><strong>experimental!</strong> With additional conditions:</p><pre><code class="language-julia">models() do model
    matching(model, X, y)) &amp;&amp;
    model.prediction_type == :probabilistic &amp;&amp;
	model.is_pure_julia
end</code></pre><p><code>tree = @load DecisionTreeClassifier</code> to load code and instantiate &quot;DecisionTreeClassifier&quot; model</p><p><code>tree2  = DecisionTreeClassifier(max_depth=2)</code> instantiates a model type already in scope</p><p><code>ridge = @load RidgeRegressor pkg=MultivariateStats</code> loads and instantiates a model provided by multiple packages</p><h4><a class="nav-anchor" id="Scitypes-and-coercion-1" href="#Scitypes-and-coercion-1">Scitypes and coercion</a></h4><p><code>scitype(x)</code> is the scientific type of <code>x</code>. For example <code>scitype(2.4) = Continuous</code></p><p><img src="../scitypes_small.png" alt="scitypes.png"/></p><table><tr><th style="text-align: right">type</th><th style="text-align: right">scitype</th></tr><tr><td style="text-align: right"><code>AbstractFloat</code></td><td style="text-align: right"><code>Continuous</code></td></tr><tr><td style="text-align: right"><code>Integer</code></td><td style="text-align: right"><code>Count</code></td></tr><tr><td style="text-align: right"><code>CategoricalValue</code> and <code>CategoricalString</code></td><td style="text-align: right"><code>Multiclass</code> or <code>OrderedFactor</code></td></tr></table><p><em>Figure and Table for scalar scitypes</em></p><p>Use <code>schema(X)</code> to get the column scitypes of a table <code>X</code></p><p><code>coerce(y, Multiclass)</code> attempts coercion of all elements of <code>y</code> into scitype <code>Multiclass</code></p><p><code>coerce(X, :x1 =&gt; Continuous, :x2 =&gt; OrderedFactor)</code> to coerce columns <code>:x1</code> and <code>:x2</code> of table <code>X</code>.</p><h3><a class="nav-anchor" id="Ingesting-data-1" href="#Ingesting-data-1">Ingesting data</a></h3><p>Splitting any table into target and input (note semicolon):</p><pre><code class="language-julia">using RDatasets
channing = dataset(&quot;boot&quot;, &quot;channing&quot;)
y, X =  unpack(channing,
               ==(:Exit),            # y is the :Exit column
               !=(:Time);            # X is the rest, except :Time
               :Exit=&gt;Continuous,    # correct wrong scitypes
               :Entry=&gt;Continuous,
               :Cens=&gt;Multiclass)</code></pre><p>Splitting row indices into train/validation/test:</p><p><code>train, valid, test = partition(eachindex(y), 0.7, 0.2, shuffle=true, rng=1234)</code> for 70:20:10 ratio</p><h4><a class="nav-anchor" id="Machine-construction-1" href="#Machine-construction-1">Machine construction</a></h4><p>Supervised case:</p><p><code>model = KNNRegressor(K=1)</code> and <code>mach = machine(model, X, y)</code></p><p>Unsupervised case:</p><p><code>model = OneHotEncoder()</code> and <code>mach = machine(model, X)</code></p><h4><a class="nav-anchor" id="Fitting-1" href="#Fitting-1">Fitting</a></h4><p><code>fit!(mach, rows=1:100, verbosity=1, force=false)</code></p><h4><a class="nav-anchor" id="Prediction-1" href="#Prediction-1">Prediction</a></h4><p>Supervised case: <code>predict(mach, Xnew)</code> or <code>predict(mach, rows=1:100)</code></p><p>Similarly, for probabilistic models: <code>predict_mode</code>, <code>predict_mean</code> and <code>predict_median</code>.</p><p>Unsupervised case: <code>transform(mach, rows=1:100)</code> or <code>inverse_transform(mach, rows)</code>, etc.</p><h4><a class="nav-anchor" id="Inspecting-objects-1" href="#Inspecting-objects-1">Inspecting objects</a></h4><p><code>@more</code> gets detail on last object in REPL</p><p><code>params(model)</code> gets nested-tuple of all hyperparameters, even nested ones</p><p><code>info(ConstantRegresssor())</code>, <code>info(&quot;PCA&quot;)</code>, <code>info(&quot;RidgeRegressor&quot;, pkg=&quot;MultivariateStats&quot;)</code> gets all properties (aka traits) of registered models</p><p><code>info(rms)</code> gets all properties of a performance measure</p><p><code>schema(X)</code> get column names, types and scitypes, and nrows, of a table <code>X</code></p><p><code>scitype(model)</code>, <code>scitype(rms)</code>, <code>scitype(X)</code> gets scientific type of a model, measure or table (encoding key properties)</p><p><code>fitted_params(mach)</code> gets learned parameters of fitted machine</p><p><code>report(mach)</code> gets other training results (e.g. feature rankings)</p><h4><a class="nav-anchor" id="Resampling-strategies-1" href="#Resampling-strategies-1">Resampling strategies</a></h4><p><code>Holdout(fraction_train=…, shuffle=false)</code> for simple holdout</p><p><code>CV(nfolds=6, shuffle=false)</code> for cross-validation</p><p>or a list of pairs of row indices:</p><p><code>[(train1, eval1), (train2, eval2), ... (traink, evalk)]</code></p><h4><a class="nav-anchor" id="Performance-estimation-1" href="#Performance-estimation-1">Performance estimation</a></h4><p><code>evaluate(model, X, y, resampling=CV(), measure=rms, operation=predict, weights=..., verbosity=1)</code> <code>evaluate!(mach, resampling=Holdout(), measure=[rms, mav], operation=predict, weights=..., verbosity=1)</code> <code>evaluate!(mach, resampling=[(fold1, fold2), (fold2, fold1)], measure=rms)</code></p><h4><a class="nav-anchor" id="Ranges-for-tuning-1" href="#Ranges-for-tuning-1">Ranges for tuning</a></h4><p>If <code>r = range(KNNRegressor(), :K, lower=1, upper = 20, scale=:log)</code> then <code>iterator(r, 6) = [1, 2, 3, 6, 11, 20]</code></p><p>Non-numeric ranges: <code>r = range(model, :parameter, values=…)</code>.</p><p>Nested ranges: Use dot syntax, as in <code>r = range(EnsembleModel(atom=tree), :(atom.max_depth), ...)</code></p><h4><a class="nav-anchor" id="Tuning-strategies-1" href="#Tuning-strategies-1">Tuning strategies</a></h4><p><code>Grid(resolution=10)</code> for grid search</p><h4><a class="nav-anchor" id="Tuning-model-wrapper-1" href="#Tuning-model-wrapper-1">Tuning model wrapper</a></h4><p><code>tuned_model = TunedModel(model=…, tuning=Grid(), resampling=Holdout(), measure=…, operation=predict, ranges=…, minimize=true, full_report=true)</code></p><h4><a class="nav-anchor" id="Learning-curves-1" href="#Learning-curves-1">Learning curves</a></h4><p><code>curve = learning_curve!(mach, resolution=30, resampling=Holdout(), measure=…, operation=predict, range=…, n=1)</code></p><p>If using Plots.jl:</p><p><code>plot(curve.parameter_values, curve.measurements, xlab=curve.parameter_name, xscale=curve.parameter_scale)</code></p><h4><a class="nav-anchor" id="Built-in-performance-measures-1" href="#Built-in-performance-measures-1">Built-in performance measures</a></h4><p><code>l1</code>, <code>l2</code>, <code>mav</code>, <code>rms</code>, <code>rmsl</code>, <code>rmslp1</code>, <code>rmsp</code>, <code>misclassification_rate</code>, <code>cross_entropy</code></p><p><code>info(rms)</code> to list properties (aka traits) of the <code>rms</code> measure</p><p><code>using LossFunctions</code> to use more measures</p><h4><a class="nav-anchor" id="Transformers-1" href="#Transformers-1">Transformers</a></h4><p>Built-ins include: <code>Standardizer</code>, <code>OneHotEncoder</code>, <code>UnivariateBoxCoxTransformer</code>, <code>FeatureSelector</code>, <code>UnivariateStandardizer</code></p><p>Externals include: <code>PCA</code> (in MultivariateStats), <code>KMeans</code>, <code>KMedoids</code> (in Clustering).</p><p>Full list: do <code>models(m -&gt; !m[:is_supervised])</code></p><h4><a class="nav-anchor" id="Ensemble-model-wrapper-1" href="#Ensemble-model-wrapper-1">Ensemble model wrapper</a></h4><p><code>EnsembleModel(atom=…, weights=Float64[], bagging_fraction=0.8, rng=GLOBAL_RNG, n=100, parallel=true, out_of_bag_measure=[])</code></p><h4><a class="nav-anchor" id="Pipelines-1" href="#Pipelines-1">Pipelines</a></h4><p>With point predictions:</p><p><code>pipe = @pipeline MyPipe(hot=OneHotEncoder(), knn=KNNRegressor(K=3), target=UnivariateStandardizer())</code></p><p>With probabilistic-predictions:</p><p><code>pipe = @pipeline MyPipe(hot=OneHotEncoder(), knn=KNNRegressor(K=3), target=v-&gt;log.(V), inverse=v-&gt;exp.(v)) is_probabilistic=true</code></p><p>Unsupervised:</p><p><code>pipe = @pipeline MyPipe(stand=Standardizer(), hot=OneHotEncoder())</code></p><h4><a class="nav-anchor" id="Define-a-supervised-learning-network:-1" href="#Define-a-supervised-learning-network:-1">Define a supervised learning network:</a></h4><p><code>Xs = source(X)</code> <code>ys = source(y, kind=:target)</code></p><p>... define further nodal machines and nodes ...</p><p><code>yhat = predict(knn_machine, W, ys)</code> (final node)</p><h4><a class="nav-anchor" id="Exporting-a-learning-network-as-stand-alone-model:-1" href="#Exporting-a-learning-network-as-stand-alone-model:-1">Exporting a learning network as stand-alone model:</a></h4><p>Supervised, with final node <code>yhat</code> returning point-predictions:</p><p><code>@from_network Composite(pca=network_pca, knn=network_knn) &lt;= yhat</code></p><p>Supervised, with <code>yhat</code> final node returning probabilistic predictions:</p><p><code>@from_network Composite(knn=network_knn) &lt;= yhat is_probabilistic=true</code></p><p>Unsupervised, with final node <code>Xout</code>:</p><p><code>@from_network Composite(pca=network_pca) &lt;= Xout</code></p><footer><hr/><a class="previous" href="../api/"><span class="direction">Previous</span><span class="title">API</span></a><a class="next" href="../NEWS/"><span class="direction">Next</span><span class="title">MLJ News</span></a></footer></article></body></html>
