<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Simple User Defined Models · MLJ</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLJ</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><a class="toctext" href="../working_with_tasks/">Working with Tasks</a></li><li><a class="toctext" href="../learning_networks/">Learning Networks</a></li><li class="current"><a class="toctext" href>Simple User Defined Models</a><ul class="internal"></ul></li><li><a class="toctext" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="toctext" href="../internals/">Internals</a></li><li><a class="toctext" href="../glossary/">Glossary</a></li><li><a class="toctext" href="../api/">API</a></li><li><a class="toctext" href="../frequently_asked_questions/">FAQ</a></li><li><a class="toctext" href="../NEWS/">MLJ News</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Simple User Defined Models</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/simple_user_defined_models.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Simple User Defined Models</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Simple-User-Defined-Models-1" href="#Simple-User-Defined-Models-1">Simple User Defined Models</a></h1><p>To quickly implement a new supervised model in MLJ, it suffices to:</p><ul><li>Define a <code>mutable struct</code> to store hyperparameters. This is either a subtype of <code>Probabilistic{Any}</code> or <code>Deterministic{Any}</code>, depending on whether probabilistic or ordinary point predictions are intended. This <code>struct</code> is the <em>model</em>.</li><li>Define a <code>fit</code> method, dispatched on the model, returning learned parameters, also known as the <em>fit-result</em>.</li><li>Define a <code>predict</code> method, dispatched on the model, and passed the fit-result, to return predictions on new patterns.</li></ul><p>In the examples below, the training input <code>X</code> of <code>fit</code>, and the new input <code>Xnew</code> passed to <code>predict</code>, are tables. Each training target <code>y</code> is a <code>Vector</code> or <code>CategoricalVector</code>, according to its <a href="../">scientific type</a>, or a table in the multivariate case. </p><p>The predicitions returned by <code>predict</code> have the same form as <code>y</code> for deterministic models, but are <code>Vector</code>s of distibutions for probabilistic models.</p><p>For your models to implement an optional <code>update</code> method, to buy into the MLJ logging protocol, or report training statistics or other model-specific functionality, a <code>fit</code> method with a slightly different signature and output is required. To enable checks of the scientific type of data passed to your model by MLJ&#39;s meta-algorithms, one needs to implement additional traits. A <code>clean!</code> method can be defined to check that hyperparameter values are within normal ranges. For details, see <a href="../adding_models_for_general_use/">Adding Models for General Use</a>.</p><p>For an unsupervised model, implement <code>transform</code> and, optionally, <code>inverse_transform</code> using the same signature at `predict below.</p><h3><a class="nav-anchor" id="A-simple-deterministic-regressor-1" href="#A-simple-deterministic-regressor-1">A simple deterministic regressor</a></h3><p>Here&#39;s a quick-and-dirty implementation of a ridge regressor with no intercept:</p><pre><code class="language-julia">import MLJBase
using LinearAlgebra

mutable struct MyRegressor &lt;: MLJBase.Deterministic{Any}
    lambda::Float64
end

# fit returns coefficients minimizing a penalized rms loss function:
function MLJBase.fit(model::MyRegressor, X, y)
    x = MLJBase.matrix(X)                     # convert table to matrix
    fitresult = (x&#39;x - model.lambda*I)\(x&#39;y)  # the coefficients
    return fitresult
end

# predict uses coefficients to make new prediction:
MLJBase.predict(model::MyRegressor, fitresult, Xnew) = MLJBase.matrix(Xnew)fitresult</code></pre><p>After loading this code, all MLJ&#39;s basic meta-algorithms can be applied to <code>MyRegressor</code>:</p><pre><code class="language-julia">julia&gt; using MLJ
julia&gt; task = load_boston()
julia&gt; model = MyRegressor(1.0)
julia&gt; regressor = machine(model, task)
julia&gt; evaluate!(regressor, resampling=CV(), measure=rms) |&gt; mean
7.434221318358656
</code></pre><h3><a class="nav-anchor" id="A-simple-probabilistic-classifier-1" href="#A-simple-probabilistic-classifier-1">A simple probabilistic classifier</a></h3><p>The following probabilistic model simply fits a probability distribution to the <code>MultiClass</code> training target (i.e., ignores <code>X</code>) and returns this pdf for any new pattern:</p><pre><code class="language-julia">import MLJBase
import Tables
import Distributions

struct MyClassifier &lt;: MLJBase.Probabilistic{Any}
end

# `fit` ignores the inputs X and returns the training target y
# probability distribution:
function MLJBase.fit(model::MyClassifier, X, y)
    fitresult = Distributions.fit(MLJBase.UnivariateNominal, y)
    return fitresult
end

# `predict` retunrs the passed fitresult (pdf) for all new patterns:
function MLJBase.predict(model::MyClassifier, fitresult, Xnew)
    row_iterator = Tables.rows(Xnew)
    return [fitresult for r in row_iterator]
end</code></pre><p>For more details on the <code>UnivariateNominal</code> distribution, query <code>MLJBase.UnivariateNominal</code>.</p><footer><hr/><a class="previous" href="../learning_networks/"><span class="direction">Previous</span><span class="title">Learning Networks</span></a><a class="next" href="../adding_models_for_general_use/"><span class="direction">Next</span><span class="title">Adding Models for General Use</span></a></footer></article></body></html>
