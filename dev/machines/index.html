<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Machines · MLJ</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLJ</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><a class="toctext" href="../common_mlj_workflows/">Common MLJ Workflows</a></li><li><a class="toctext" href="../model_search/">Model Search</a></li><li class="current"><a class="toctext" href>Machines</a><ul class="internal"></ul></li><li><a class="toctext" href="../evaluating_model_performance/">Evaluating Model Performance</a></li><li><a class="toctext" href="../performance_measures/">Performance Measures</a></li><li><a class="toctext" href="../tuning_models/">Tuning Models</a></li><li><a class="toctext" href="../built_in_transformers/">Built-in Transformers</a></li><li><a class="toctext" href="../composing_models/">Composing Models</a></li><li><a class="toctext" href="../homogeneous_ensembles/">Homogeneous Ensembles</a></li><li><a class="toctext" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="toctext" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="toctext" href="../benchmarking/">Benchmarking</a></li><li><a class="toctext" href="../working_with_tasks/">Working with Tasks</a></li><li><a class="toctext" href="../internals/">Internals</a></li><li><a class="toctext" href="../glossary/">Glossary</a></li><li><a class="toctext" href="../api/">API</a></li><li><a class="toctext" href="../mlj_cheatsheet/">MLJ Cheatsheet</a></li><li><a class="toctext" href="../NEWS/">MLJ News</a></li><li><a class="toctext" href="../frequently_asked_questions/">FAQ</a></li><li><a class="toctext" href="../julia_blogpost/">Julia BlogPost</a></li><li><a class="toctext" href="../acceleration_and_parallelism/">Acceleration and Parallelism</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Machines</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/machines.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Machines</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Machines-1" href="#Machines-1">Machines</a></h1><p>Under the hood, calling <code>fit!</code> on a machine calls either <code>MLJBase.fit</code> or <code>MLJBase.update</code>, depending on the machine&#39;s internal state, as recorded in additional fields <code>previous_model</code> and <code>previous_rows</code>. These lower-level <code>fit</code> and <code>update</code> methods dispatch on the model and a view of the data defined by the optional <code>rows</code> keyword argument of <code>fit!</code> (all rows by default). In this way, if a model <code>update</code> method is implemented, calls to <code>fit!</code> can avoid redundant calculations for certain kinds of model mutations (eg, increasing the number of epochs in a neural network).</p><p>The interested reader can learn more on machine internals by examining the simplified code excerpt in <a href="../internals/">Internals</a>.</p><pre><code class="language-julia">forest = EnsembleModel(atom=(@load DecisionTreeClassifier), n=10);
X, y = @load_iris;
mach = machine(forest, X, y)
fit!(mach, verbosity=2);</code></pre><pre><code class="language-none">Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07
</code></pre><p>Generally, changing a hyperparameter triggers retraining on calls to subsequent <code>fit!</code>:</p><pre><code class="language-julia-repl">julia&gt; forest.bagging_fraction=0.5
0.5

julia&gt; fit!(mach, verbosity=2);
[ Info: Updating Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07.
[ Info: One hash per new atom trained: 
##########</code></pre><p>However, for this iterative model, increasing the iteration parameter only adds models to the existing ensemble:</p><pre><code class="language-julia-repl">julia&gt; forest.n=15
15

julia&gt; fit!(mach, verbosity=2);
[ Info: Updating Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07.
[ Info: Building on existing ensemble of length 10
[ Info: One hash per new atom trained: 
#####</code></pre><p>Call <code>fit!</code> again without making a change and no retraining occurs:</p><pre><code class="language-julia-repl">julia&gt; fit!(mach);
┌ Info: Not retraining Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07.
└  It appears up-to-date. Use `force=true` to force retraining.</code></pre><p>However, retraining can be forced:</p><pre><code class="language-julia-repl">julia&gt; fit!(mach, force=true);
[ Info: Training Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07.</code></pre><p>And is retriggered if the view of the data changes:</p><pre><code class="language-julia-repl">julia&gt; fit!(mach, rows=1:100);
[ Info: Training Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07.</code></pre><pre><code class="language-julia-repl">julia&gt; fit!(mach, rows=1:100);
┌ Info: Not retraining Machine{ProbabilisticEnsembleModel{DecisionTreeClassifier}} @ 1…07.
└  It appears up-to-date. Use `force=true` to force retraining.</code></pre><p>For a supervised machine the <code>predict</code> method calls a lower-level <code>MLJBase.predict</code> method, dispatched on the underlying model and the <code>fitresult</code> (see below). To see <code>predict</code> in action, as well as its unsupervised cousins <code>transform</code> and <code>inverse_transform</code>, see <a href="../">Getting Started</a>.</p><p>Here is a complete list of the fields of a machine:</p><ul><li><p><code>model</code> - the struct containing the hyperparameters to be used in calls to <code>fit!</code></p></li><li><p><code>fitresult</code> - the learned parameters in a raw form, initially undefined</p></li><li><p><code>args</code> -  a tuple of the data (in the supervised learning example above, <code>args = (X, y)</code>)</p></li><li><p><code>report</code> - outputs of training not encoded in <code>fitresult</code> (eg, feature rankings)</p></li><li><p><code>previous_model</code> - a deep copy of the model used in the last call to <code>fit!</code></p></li><li><p><code>previous_rows</code> -  a copy of the row indices used in last call to <code>fit!</code></p></li><li><p><code>cache</code></p></li></ul><p>Instead of data <code>X</code> and <code>y</code>, the <code>machine</code> constructor can be provided <code>Node</code> or <code>Source</code> objects (&quot;dynamic data&quot;) to obtain a <code>NodalMachine</code>, rather than a regular <code>Machine</code> object, which includes the same fields listed above. See <a href="../composing_models/">Composing Models</a> for more on this advanced feature.</p><h3><a class="nav-anchor" id="API-Reference-1" href="#API-Reference-1">API Reference</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.fit!" href="#StatsBase.fit!"><code>StatsBase.fit!</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">fit!(mach::Machine; rows=nothing, verbosity=1, force=false)</code></pre><p>When called for the first time, call <code>MLJBase.fit</code> on <code>mach.model</code> and store the returned fit-result and report. Subsequent calls do nothing unless: (i) <code>force=true</code>, or (ii) the specified <code>rows</code> are different from those used the last time a fit-result was computed, or (iii) <code>mach.model</code> has changed since the last time a fit-result was computed (the machine is <em>stale</em>). In cases (i) or (ii) <code>MLJBase.fit</code> is called on <code>mach.model</code>. Otherwise, <code>MLJBase.update</code> is called.</p><pre><code class="language-none">fit!(mach::NodalMachine; rows=nothing, verbosity=1, force=false)</code></pre><p>When called for the first time, attempt to call <code>MLJBase.fit</code> on <code>fit.model</code>. This will fail if an argument of the machine depends ultimately on some other untrained machine for successful calling, but this is resolved by instead calling <code>fit!</code> on fitting any node <code>N</code> for which <code>mach in machines(N)</code> is true, which trains all necessary machines in an appropriate order. Subsequent <code>fit!</code> calls do nothing unless: (i) <code>force=true</code>, or (ii) some machine on which <code>mach</code> depends has computed a new fit-result since <code>mach</code> last computed its fit-result, or (iii) the specified <code>rows</code> have changed since the last time a fit-result was last computed, or (iv) <code>mach</code> is stale (see below). In cases (i), (ii) or (iii), <code>MLJBase.fit</code> is called. Otherwise <code>MLJBase.update</code> is called.</p><p>A machine <code>mach</code> is <em>stale</em> if <code>mach.model</code> has changed since the last time a fit-result was computed, or if if one of its training arguments is <code>stale</code>. A node <code>N</code> is stale if <code>N.machine</code> is stale or one of its arguments is stale. Source nodes are never stale.</p><p>Note that a nodal machine obtains its training data by <em>calling</em> its node arguments on the specified <code>rows</code> (rather than <em>indexing</em> its arguments on those rows) and that this calling is a recursive operation on nodes upstream of those arguments.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/23bb4b5baf4089878267c11f6be2384c54acf037/src/machines.jl#L73-L108">source</a><div><div><pre><code class="language-julia">fit!(N::Node; rows=nothing, verbosity::Int=1, force::Bool=false)</code></pre><p>Train all machines in the learning network terminating at node <code>N</code>, in an appropriate order. These machines are those returned by <code>machines(N)</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/23bb4b5baf4089878267c11f6be2384c54acf037/src/networks.jl#L299-L305">source</a></section><footer><hr/><a class="previous" href="../model_search/"><span class="direction">Previous</span><span class="title">Model Search</span></a><a class="next" href="../evaluating_model_performance/"><span class="direction">Next</span><span class="title">Evaluating Model Performance</span></a></footer></article></body></html>
