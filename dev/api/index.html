<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · MLJ</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLJ</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><a class="toctext" href="../working_with_tasks/">Working with Tasks</a></li><li><a class="toctext" href="../learning_networks/">Learning Networks</a></li><li><a class="toctext" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="toctext" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="toctext" href="../internals/">Internals</a></li><li><a class="toctext" href="../glossary/">Glossary</a></li><li class="current"><a class="toctext" href>API</a><ul class="internal"></ul></li><li><a class="toctext" href="../frequently_asked_questions/">FAQ</a></li><li><a class="toctext" href="../NEWS/">MLJ News</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>API</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/api.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>API</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="API-1" href="#API-1">API</a></h1><h3><a class="nav-anchor" id="Functions-1" href="#Functions-1">Functions</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.EnsembleModel-Tuple{}" href="#MLJ.EnsembleModel-Tuple{}"><code>MLJ.EnsembleModel</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">EnsembleModel(atom=nothing, weights=Float64[], bagging_fraction=0.8, rng_seed=0, n=100, parallel=true)</code></pre><p>Create a model for training an ensemble of <code>n</code> learners, with optional bagging, each with associated model <code>atom</code>. Ensembling is useful if <code>fit!(machine(atom, data...))</code> does not create identical models on repeated calls (ie, is a stochastic model, such as a decision tree with randomized node selection criteria), or if <code>bagging_fraction</code> is set to a value less than 1.0, or both. The constructor fails if no <code>atom</code> is specified.</p><p>Predictions are weighted according to the vector <code>weights</code> (to allow for external optimization) except in the case that <code>atom</code> is a <code>Deterministic</code> classifier. Uniform weights are used if <code>weight</code> has zero length.</p><p>The ensemble model is <code>Deterministic</code> or <code>Probabilistic</code>, according to the corresponding supertype of <code>atom</code>. In the case of deterministic classifiers (<code>target_scitype(atom) &lt;: Union{Multiclass,FiniteOrderedFactor}</code>), the predictions are majority votes, and for regressors (<code>target_scitype(atom)&lt;: Continuous</code>) they are ordinary averages. Probabilistic predictions are obtained by averaging the atomic probability distribution/mass functions; in particular, for regressors, the ensemble prediction on each input pattern has the type <code>MixtureModel{VF,VS,D}</code> from the Distributions.jl package, where <code>D</code> is the type of predicted distribution for <code>atom</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/ensembles.jl#L234-L261">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.TunedModel-Tuple{}" href="#MLJ.TunedModel-Tuple{}"><code>MLJ.TunedModel</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">tuned_model = TunedModel(; model=nothing,
                         tuning=Grid(),
                         resampling=Holdout(),
                         measure=nothing,
                         operation=predict,
                         nested_ranges=NamedTuple(),
                         minimize=true,
                         full_report=true)</code></pre><p>Construct a model wrapper for hyperparameter optimization of a supervised learner.</p><p>Calling <code>fit!(mach)</code> on a machine <code>mach=machine(tuned_model, X, y)</code> will: (i) Instigate a search, over clones of <code>model</code> with the hyperparameter mutations specified by <code>nested_ranges</code>, for that model optimizing the specified <code>measure</code>, according to evaluations carried out using the specified <code>tuning</code> strategy and <code>resampling</code> strategy; and (ii) Fit a machine, <code>mach_optimal = mach.fitresult</code>, wrapping the optimal <code>model</code> object in <em>all</em> the provided data <code>X, y</code>. Calling <code>predict(mach, Xnew)</code> then returns predictions on <code>Xnew</code> of the machine <code>mach_optimal</code>.</p><p>If <code>measure</code> is a score, rather than a loss, specify <code>minimize=false</code>.</p><p>The optimal clone of <code>model</code> is accessible as <code>fitted_params(mach).best_model</code>. In the case of two-parameter tuning, a Plots.jl plot of performance estimates is returned by <code>plot(mach)</code> or <code>heatmap(mach)</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/tuning.jl#L39-L69">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.evaluate!-Tuple{Machine}" href="#MLJ.evaluate!-Tuple{Machine}"><code>MLJ.evaluate!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">evaluate!(mach, resampling=CV(), measure=nothing, operation=predict, verbosity=1)</code></pre><p>Estimate the performance of a machine <code>mach</code> using the specified <code>resampling</code> strategy (defaulting to 6-fold cross-validation) and <code>measure</code>, which can be a single measure or vector. </p><p>Although evaluate! is mutating, <code>mach.model</code> and <code>mach.args</code> are preserved.</p><p>Resampling and testing is based exclusively on data in <code>rows</code>, when specified.</p><p>If no measure is specified, then <code>default_measure(mach.model)</code> is used, unless this default is <code>nothing</code> and an error is thrown.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/resampling.jl#L44-L60">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.iterator-Union{Tuple{M}, Tuple{M,NamedTuple}} where M&lt;:Model" href="#MLJ.iterator-Union{Tuple{M}, Tuple{M,NamedTuple}} where M&lt;:Model"><code>MLJ.iterator</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">iterator(model::Model, param_iterators::NamedTuple)</code></pre><p>Iterator over all models of type <code>typeof(model)</code> defined by <code>param_iterators</code>.</p><p>Each <code>name</code> in the nested <code>:name =&gt; value</code> pairs of <code>param_iterators</code> should be the name of a (possibly nested) field of <code>model</code>; and each element of <code>flat_values(param_iterators)</code> (the corresponding final values) is an iterator over values of one of those fields.</p><p>See also <code>iterator</code> and <code>params</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L316-L329">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.learning_curve!-Tuple{Machine{#s74} where #s74&lt;:Supervised}" href="#MLJ.learning_curve!-Tuple{Machine{#s74} where #s74&lt;:Supervised}"><code>MLJ.learning_curve!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">curve = learning_curve!(mach; resolution=30, resampling=Holdout(), measure=rms, operation=predict, nested_range=nothing, n=1)</code></pre><p>Given a supervised machine <code>mach</code>, returns a named tuple of objects needed to generate a plot of performance measurements, as a function of the single hyperparameter specified in <code>nested_range</code>. The tuple <code>curve</code> has the following keys: <code>:parameter_name</code>, <code>:parameter_scale</code>, <code>:parameter_values</code>, <code>:measurements</code>.</p><p>For <code>n</code> not equal to 1, multiple curves are computed, and the value of <code>curve.measurements</code> is an array, one column for each run. This is useful in the case of models with indeterminate fit-results, such as a random forest.</p><pre><code class="language-julia">X, y = datanow()
atom = RidgeRegressor()
ensemble = EnsembleModel(atom=atom)
mach = machine(ensemble, X, y)
r_lambda = range(atom, :lambda, lower=0.1, upper=100, scale=:log10)
curve = MLJ.learning_curve!(mach; nested_range=(atom=(lambda=r_lambda,),))
using Plots
plot(curve.parameter_values, curve.measurements, xlab=curve.parameter_name, xscale=curve.parameter_scale)</code></pre><p>Smart fitting applies. For example, if the model is an ensemble model, and the hyperparemeter parameter is <code>n</code>, then atomic models are progressively added to the ensemble, not recomputed from scratch for each new value of <code>n</code>.</p><pre><code class="language-julia">atom.lambda=1.0
r_n = range(ensemble, :n, lower=2, upper=150)
curves = MLJ.learning_curve!(mach; nested_range=(n=r_n,), verbosity=3, n=5)
plot(curves.parameter_values, curves.measurements, xlab=curves.parameter_name)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/tuning.jl#L241-L278">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.rmsp-Tuple{AbstractArray{#s12,1} where #s12&lt;:Real,Any}" href="#MLJ.rmsp-Tuple{AbstractArray{#s12,1} where #s12&lt;:Real,Any}"><code>MLJ.rmsp</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Root mean squared percentage loss </p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/metrics.jl#L69">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.sources-Tuple{MLJ.Source}" href="#MLJ.sources-Tuple{MLJ.Source}"><code>MLJ.sources</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">sources(N)</code></pre><p>Return a list of all ultimate sources of  a node <code>N</code>. </p><p>See also: node, source</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/networks.jl#L22-L29">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.info-Tuple{String}" href="#MLJBase.info-Tuple{String}"><code>MLJBase.info</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>info(model, pkg=nothing)</p><p>Return the dictionary of metadata associated with <code>model::String</code>. If more than one package implements <code>model</code> then <code>pkg::String</code> will need to be specified.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/loading.jl#L21-L28">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.fit!-Tuple{MLJ.AbstractMachine}" href="#StatsBase.fit!-Tuple{MLJ.AbstractMachine}"><code>StatsBase.fit!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">fit!(mach::Machine; rows=nothing, verbosity=1)</code></pre><p>Train the machine <code>mach</code> using the algorithm and hyperparameters specified by <code>mach.model</code>, using those rows of the wrapped data having indices in <code>rows</code>.</p><pre><code class="language-none">fit!(mach::NodalMachine; rows=nothing, verbosity=1)</code></pre><p>A nodal machine is trained in the same way as a regular machine with one difference: Instead of training the model on the wrapped data <em>indexed</em> on <code>rows</code>, it is trained on the wrapped nodes <em>called</em> on <code>rows</code>, with calling being a recursive operation on nodes within a learning network.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/machines.jl#L79-L94">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.@curve-Tuple{Any,Any,Any}" href="#MLJ.@curve-Tuple{Any,Any,Any}"><code>MLJ.@curve</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><p><strong><code>@curve</code></strong></p><p>The code,</p><pre><code class="language-none">@curve var range code</code></pre><p>evaluates <code>code</code>, replacing appearances of <code>var</code> therein with each value in <code>range</code>. The range and corresponding evaluations are returned as a tuple of arrays. For example,</p><pre><code class="language-none">@curve  x 1:3 (x^2 + 1)</code></pre><p>evaluates to</p><pre><code class="language-none">([1,2,3], [2, 5, 10])</code></pre><p>This is convenient for plotting functions using, eg, the <code>Plots</code> package:</p><pre><code class="language-none">plot(@curve x 1:3 (x^2 + 1))</code></pre><p>A macro <code>@pcurve</code> parallelizes the same behaviour.  A two-variable implementation is also available, operating as in the following example:</p><pre><code class="language-none">julia&gt; @curve x [1,2,3] y [7,8] (x + y)
([1,2,3],[7 8],[8.0 9.0; 9.0 10.0; 10.0 11.0])

julia&gt; ans[3]
3×2 Array{Float64,2}:
  8.0   9.0
  9.0  10.0
 10.0  11.0</code></pre><p>N.B. The second range is returned as a <em>row</em> vector for consistency with the output matrix. This is also helpful when plotting, as in:</p><pre><code class="language-none">julia&gt; u1, u2, A = @curve x range(0, stop=1, length=100) α [1,2,3] x^α
julia&gt; u2 = map(u2) do α &quot;α = &quot;*string(α) end
julia&gt; plot(u1, A, label=u2)</code></pre><p>which generates three superimposed plots - of the functions x, x^2 and x^3 - each labels with the exponents α = 1, 2, 3 in the legend.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/utilities.jl#L58-L102">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.SimpleDeterministicCompositeModel" href="#MLJ.SimpleDeterministicCompositeModel"><code>MLJ.SimpleDeterministicCompositeModel</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">SimpleDeterministicCompositeModel(;regressor=ConstantRegressor(), 
                          transformer=FeatureSelector())</code></pre><p>Construct a composite model consisting of a transformer (<code>Unsupervised</code> model) followed by a <code>Deterministic</code> model. Mainly intended for internal testing .</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/composites.jl#L12-L20">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.copy" href="#Base.copy"><code>Base.copy</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">copy(params::NamedTuple, values=nothing)</code></pre><p>Return a copy of <code>params</code> with new <code>values</code>. That is, <code>flat_values(copy(params, values)) == values</code> is true, while the nested keys remain unchanged.</p><p>If <code>values</code> is not specified a deep copy is returned. </p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L69-L78">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.merge!-Tuple{Array{T,1} where T,Array{T,1} where T}" href="#Base.merge!-Tuple{Array{T,1} where T,Array{T,1} where T}"><code>Base.merge!</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">merge!(tape1, tape2)</code></pre><p>Incrementally appends to <code>tape1</code> all elements in <code>tape2</code>, excluding any element previously added (or any element of <code>tape1</code> in its initial state).</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/networks.jl#L36-L44">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.range-Union{Tuple{D}, Tuple{MLJType,Symbol}} where D" href="#Base.range-Union{Tuple{D}, Tuple{MLJType,Symbol}} where D"><code>Base.range</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">r = range(model, :hyper; values=nothing)</code></pre><p>Defines a <code>NominalRange</code> object for a field <code>hyper</code> of <code>model</code>. Note that <code>r</code> is not directly iterable but <code>iterator(r)</code> iterates over <code>values</code>.</p><pre><code class="language-none">r = range(model, :hyper; upper=nothing, lower=nothing, scale=:linear)</code></pre><p>Defines a <code>NumericRange</code> object for a field <code>hyper</code> of <code>model</code>.  Note that <code>r</code> is not directly iteratable but <code>iterator(r, n)</code> iterates over <code>n</code> values between <code>lower</code> and <code>upper</code> values, according to the specified <code>scale</code>. The supported scales are <code>:linear, :log, :log10, :log2</code>. Values for <code>Integer</code> types are rounded (with duplicate values removed, resulting in possibly less than <code>n</code> values).</p><p>Alternatively, if a function <code>f</code> is provided as <code>scale</code>, then <code>iterator(r, n)</code> iterates over the values <code>[f(x1), f(x2), ... , f(xn)]</code>, where <code>x1, x2, ..., xn</code> are linearly spaced between <code>lower</code> and <code>upper</code>.</p><p>See also: iterator</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L183-L207">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.flat_keys-Tuple{Pair{Symbol,B} where B}" href="#MLJ.flat_keys-Tuple{Pair{Symbol,B} where B}"><code>MLJ.flat_keys</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia"> flat_keys(params::NamedTuple)</code></pre><p>Use dot-concatentation to express each possibly nested key of <code>params</code> in string form.</p><p><strong>Example</strong></p><pre><code class="language-none">julia&gt; flat_keys((A=(x=2, y=3), B=9)))
[&quot;A.x&quot;, &quot;A.y&quot;, &quot;B&quot;]</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L47-L60">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.get_type-Tuple{Any,Symbol}" href="#MLJ.get_type-Tuple{Any,Symbol}"><code>MLJ.get_type</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>get_type(T, field::Symbol)</p><p>Returns the type of the field <code>field</code> of <code>DataType</code> T. Not a type-stable function.  </p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L168-L175">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.scale-Tuple{MLJ.NominalRange}" href="#MLJ.scale-Tuple{MLJ.NominalRange}"><code>MLJ.scale</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">MLJ.scale(r::ParamRange)</code></pre><p>Return the scale associated with the <code>ParamRange</code> object <code>r</code>. The possible return values are: <code>:none</code> (for a <code>NominalRange</code>), <code>:linear</code>, <code>:log</code>, <code>:log10</code>, <code>:log2</code>, or <code>:custom</code> (if <code>r.scale</code> is function).</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L221-L228">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.unwind-Tuple" href="#MLJ.unwind-Tuple"><code>MLJ.unwind</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">unwind(iterators...)</code></pre><p>Represent all possible combinations of values generated by <code>iterators</code> as rows of a matrix <code>A</code>. In more detail, <code>A</code> has one column for each iterator in <code>iterators</code> and one row for each distinct possible combination of values taken on by the iterators. Elements in the first column cycle fastest, those in the last clolumn slowest. </p><p><strong>Example</strong></p><pre><code class="language-julia">julia&gt; iterators = ([1, 2], [&quot;a&quot;,&quot;b&quot;], [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;]);
julia&gt; MLJ.unwind(iterators...)
12×3 Array{Any,2}:
 1  &quot;a&quot;  &quot;x&quot;
 2  &quot;a&quot;  &quot;x&quot;
 1  &quot;b&quot;  &quot;x&quot;
 2  &quot;b&quot;  &quot;x&quot;
 1  &quot;a&quot;  &quot;y&quot;
 2  &quot;a&quot;  &quot;y&quot;
 1  &quot;b&quot;  &quot;y&quot;
 2  &quot;b&quot;  &quot;y&quot;
 1  &quot;a&quot;  &quot;z&quot;
 2  &quot;a&quot;  &quot;z&quot;
 1  &quot;b&quot;  &quot;z&quot;
 2  &quot;b&quot;  &quot;z&quot;</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/36e11e503dbf244b3dbc3359b6e465c6a0d47214/src/parameters.jl#L265-L294">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.StratifiedKFold" href="#MLJBase.StratifiedKFold"><code>MLJBase.StratifiedKFold</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">StratifiedKFold(strata,k)</code></pre><p>Struct for StratifiedKFold provide strata&#39;s and number of partitions(k) and simply collect the object for the indices.  Taken from MLBase (https://github.com/JuliaStats/MLBase.jl).</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/utilities.jl#L65-L70">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.SupervisedTask-Tuple{Any,Any}" href="#MLJBase.SupervisedTask-Tuple{Any,Any}"><code>MLJBase.SupervisedTask</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">task = SupervisedTask(X, y; is_probabilistic=nothing, input_is_multivariate=true, target_is_multivariate=false, verbosity=1)</code></pre><p>Construct a supervised learning task with input features <code>X</code> and target <code>y</code>. Both <code>X</code> and <code>y</code> must be tables or vectors, according to whether they are multivariate or univariate. Table rows must correspond to patterns and columns to features. The boolean keyword argument <code>is_probabilistic</code> must be specified.</p><pre><code class="language-none">task = SupervisedTask(data=nothing, is_probabilistic=nothing, target=nothing, ignore=Symbol[], input_is_multivariate=true, verbosity)</code></pre><p>Construct a supervised learning task with input features <code>X</code> and target <code>y</code>, where <code>y</code> is the column vector from <code>data</code> named <code>target</code> (if this is a single symbol) or, a table whose columns are those named in <code>target</code> (if this is vector); <code>X</code> consists of all remaining columns of <code>data</code> not named in <code>ignore</code>.</p><pre><code class="language-none">X, y = task()</code></pre><p>Returns the input <code>X</code> and target <code>y</code> of the task, also available as <code>task.X</code> and <code>task.y</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/tasks.jl#L63-L85">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.UnivariateNominal" href="#MLJBase.UnivariateNominal"><code>MLJBase.UnivariateNominal</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">UnivariateNominal(prob_given_level)</code></pre><p>A discrete univariate distribution whose finite support is the set of keys of the provided dictionary, <code>prob_given_level</code>. The dictionary values specify the corresponding probabilities, which must be nonnegative and sum to one.</p><pre><code class="language-none">UnivariateNominal(levels, p)</code></pre><p>A discrete univariate distribution whose finite support is the elements of the vector <code>levels</code>, and whose corresponding probabilities are elements of the vector <code>p</code>.</p><pre><code class="language-none">levels(d::UnivariateNominal)</code></pre><p>Return the levels of <code>d</code>.</p><pre><code class="language-julia">d = UnivariateNominal([&quot;yes&quot;, &quot;no&quot;, &quot;maybe&quot;], [0.1, 0.2, 0.7])
pdf(d, &quot;no&quot;) # 0.2
mode(d) # &quot;maybe&quot;
rand(d, 5) # [&quot;maybe&quot;, &quot;no&quot;, &quot;maybe&quot;, &quot;maybe&quot;, &quot;no&quot;]
d = fit(UnivariateNominal, [&quot;maybe&quot;, &quot;no&quot;, &quot;maybe&quot;, &quot;yes&quot;])
pdf(d, &quot;maybe&quot;) ≈ 0.5 # true
levels(d) # [&quot;yes&quot;, &quot;no&quot;, &quot;maybe&quot;]</code></pre><p>If <code>v</code> is a <code>CategoricalVector</code> then <code>fit(UnivariateNominal, v)</code> includes <em>all</em> levels in pool of <code>v</code> in its support, assigning unseen levels probability zero.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/distributions.jl#L28-L60">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.UnsupervisedTask-Tuple{}" href="#MLJBase.UnsupervisedTask-Tuple{}"><code>MLJBase.UnsupervisedTask</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">task = UnsupervisedTask(data=nothing, ignore=Symbol[], input_is_multivariate=true, verbosity=1)</code></pre><p>Construct an unsupervised learning task with given input <code>data</code>, which should be a table or, in the case of univariate inputs, a single vector. </p><p>Rows of <code>data</code> must correspond to patterns and columns to features. Columns in <code>data</code> whose names appear in <code>ignore</code> are ignored.</p><pre><code class="language-none">X = task()</code></pre><p>Return the input data in form to be used in models.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/tasks.jl#L9-L24">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.column_scitypes_as_tuple-Tuple{Any}" href="#MLJBase.column_scitypes_as_tuple-Tuple{Any}"><code>MLJBase.column_scitypes_as_tuple</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">column_scitypes_as_tuple_type(X)</code></pre><p>Returns <code>Tuple{T1, T2, ..., Tn}</code> where <code>Tj</code> is the union of scitypes of elements in the <code>jth</code> column of <code>X</code>. Here <code>X</code> is any table, sparse table, or abstract matrix.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/scitypes.jl#L60-L67">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.container_type-Tuple{Any}" href="#MLJBase.container_type-Tuple{Any}"><code>MLJBase.container_type</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">container_type(X)</code></pre><p>Return <code>:table</code>, <code>:sparse</code>, or <code>:other</code>, according to whether <code>X</code> is a supported table format, a supported sparse table format, or something else.</p><p>The first two formats, together abstract vectors, support the <code>MLJBase</code> accessor methods <code>selectrows</code>, <code>selectcols</code>, <code>select</code>, <code>nrows</code>, <code>schema</code>, and <code>union_scitypes</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L142-L153">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.datanow-Tuple{}" href="#MLJBase.datanow-Tuple{}"><code>MLJBase.datanow</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Get some supervised data now!!</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/datasets.jl#L59">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.fitresult_type-Tuple{Type{#s37} where #s37&lt;:Supervised}" href="#MLJBase.fitresult_type-Tuple{Type{#s37} where #s37&lt;:Supervised}"><code>MLJBase.fitresult_type</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">MLJBase.fitresult_type(m)</code></pre><p>Returns the fitresult type of any supervised model (or model type) <code>m</code>, as declared in the model <code>mutable struct</code> declaration.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/MLJBase.jl#L206-L212">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.load_ames-Tuple{}" href="#MLJBase.load_ames-Tuple{}"><code>MLJBase.load_ames</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load the full version of the well-known Ames Housing task.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/datasets.jl#L29">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.load_boston-Tuple{}" href="#MLJBase.load_boston-Tuple{}"><code>MLJBase.load_boston</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load a well-known public regression dataset with nominal features.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/datasets.jl#L3">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.load_crabs-Tuple{}" href="#MLJBase.load_crabs-Tuple{}"><code>MLJBase.load_crabs</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load a well-known crab classification dataset with nominal features.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/datasets.jl#L49">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.load_iris-Tuple{}" href="#MLJBase.load_iris-Tuple{}"><code>MLJBase.load_iris</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load a well-known public classification task with nominal features.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/datasets.jl#L40">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.load_reduced_ames-Tuple{}" href="#MLJBase.load_reduced_ames-Tuple{}"><code>MLJBase.load_reduced_ames</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>Load a reduced version of the well-known Ames Housing task, having six numerical and six categorical features.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/datasets.jl#L13-L15">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.matrix-Tuple{Any}" href="#MLJBase.matrix-Tuple{Any}"><code>MLJBase.matrix</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">MLJBase.matrix(X)</code></pre><p>Convert a table source <code>X</code> into an <code>Matrix</code>; or, if <code>X</code> is a <code>AbstractMatrix</code>, return <code>X</code>. Optimized for column-based sources.</p><p>If instead X is a sparse table, then a <code>SparseMatrixCSC</code> object is returned. The integer relabelling of column names follows the lexicographic ordering (as indicated by <code>schema(X).names</code>).</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L167-L177">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.nrows-Tuple{Any}" href="#MLJBase.nrows-Tuple{Any}"><code>MLJBase.nrows</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">nrows(X)</code></pre><p>Return the number of rows in a table, sparse table, or abstract vector.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L285-L290">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.params-Tuple{Any}" href="#MLJBase.params-Tuple{Any}"><code>MLJBase.params</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">params(m)</code></pre><p>Recursively convert any object of subtype <code>MLJType</code> into a named tuple, keyed on the fields of <code>m</code>. The named tuple is possibly nested because <code>params</code> is recursively applied to the field values, which themselves might be <code>MLJType</code> objects. </p><p>Used, in particluar, in the case that <code>m</code> is a model, to inspect its nested hyperparameters:</p><pre><code class="language-none">julia&gt; params(EnsembleModel(atom=ConstantClassifier()))
(atom = (target_type = Bool,),
 weights = Float64[],
 bagging_fraction = 0.8,
 rng_seed = 0,
 n = 100,
 parallel = true,)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/parameters.jl#L1-L20">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.partition-Tuple{AbstractArray{Int64,1},Vararg{Any,N} where N}" href="#MLJBase.partition-Tuple{AbstractArray{Int64,1},Vararg{Any,N} where N}"><code>MLJBase.partition</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">partition(rows::AbstractVector{Int}, fractions...; shuffle=false)</code></pre><p>Splits the vector <code>rows</code> into a tuple of vectors whose lengths are given by the corresponding <code>fractions</code> of <code>length(rows)</code>. The last fraction is not provided, as it is inferred from the preceding ones. So, for example,</p><pre><code class="language-none">julia&gt; partition(1:1000, 0.2, 0.7)
(1:200, 201:900, 901:1000)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/utilities.jl#L1-L12">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.schema-Tuple{Any}" href="#MLJBase.schema-Tuple{Any}"><code>MLJBase.schema</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">schema(X)</code></pre><p>Returns a struct with properties <code>names</code>, <code>types</code> with the obvious meanings. Here <code>X</code> is any table or sparse table.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L275-L281">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.scitype-Tuple{Any}" href="#MLJBase.scitype-Tuple{Any}"><code>MLJBase.scitype</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">scitype(x)</code></pre><p>Return the scientific type for scalar values that object <code>x</code> can represent. Returns the type <code>Other</code> if <code>x</code> cannot represent scalar data.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/scitypes.jl#L16-L23">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.select-Tuple{Any,Any,Any}" href="#MLJBase.select-Tuple{Any,Any,Any}"><code>MLJBase.select</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">select(X, r, c)</code></pre><p>Select element of a table or sparse table at row <code>r</code> and column <code>c</code>. In the case of sparse data where the key <code>(r, c)</code>, zero or <code>missing</code> is returned, depending on the value type.</p><p>See also: selectrows, selectcols</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L262-L271">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.selectcols-Tuple{Any,Any}" href="#MLJBase.selectcols-Tuple{Any,Any}"><code>MLJBase.selectcols</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">selectcols(X, c)</code></pre><p>Select single or multiple columns from any table or sparse table <code>X</code>. If <code>c</code> is an abstract vector of integers or symbols, then the object returned is a table of the preferred sink type of <code>typeof(X)</code>. If <code>c</code> is a <em>single</em> integer or column, then a <code>Vector</code> or <code>CategoricalVector</code> is returned.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L249-L258">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.selectrows-Tuple{Any,Any}" href="#MLJBase.selectrows-Tuple{Any,Any}"><code>MLJBase.selectrows</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">selectrows(X, r)</code></pre><p>Select single or multiple rows from any table, sparse table, or abstract vector <code>X</code>.  If <code>X</code> is tabular, the object returned is a table of the preferred sink type of <code>typeof(X)</code>, even a single row is selected.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L237-L245">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.table-Tuple{NamedTuple}" href="#MLJBase.table-Tuple{NamedTuple}"><code>MLJBase.table</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">MLJBase.table(cols; prototype=cols)</code></pre><p>Convert a named tuple of vectors <code>cols</code>, into a table. The table type returned is the &quot;preferred sink type&quot; for <code>prototype</code> (see the Tables.jl documentation). </p><pre><code class="language-none">MLJBase.table(X::AbstractMatrix; names=nothing, prototype=nothing)</code></pre><p>Convert an abstract matrix <code>X</code> into a table with <code>names</code> (a tuple of symbols) as column names, or with labels <code>(:x1, :x2, ..., :xn)</code> where <code>n=size(X, 2)</code>, if <code>names</code> is not specified.  If prototype=nothing, then a named tuple of vectors is returned.</p><p>Equivalent to <code>table(cols, prototype=prototype)</code> where <code>cols</code> is the named tuple of columns of <code>X</code>, with <code>keys(cols) = names</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/data.jl#L200-L217">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.union_scitypes-Tuple{Any}" href="#MLJBase.union_scitypes-Tuple{Any}"><code>MLJBase.union_scitypes</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">union_scitypes(X)</code></pre><p>Return the union over all elements <code>x</code> of <code>X</code> of <code>scitype(x)</code>. Here <code>X</code> can be any table, sparse table, or abstract arrray.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/scitypes.jl#L33-L39">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.@constant-Tuple{Any}" href="#MLJBase.@constant-Tuple{Any}"><code>MLJBase.@constant</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-julia">@constant x = value</code></pre><p>Equivalent to <code>const x = value</code> but registers the binding thus:</p><pre><code class="language-none">MLJBase.HANDLE_GIVEN_ID[objectid(value)] = :x</code></pre><p>Registered objects get displayed using the variable name to which it was bound in calls to <code>show(x)</code>, etc.</p><p>WARNING: As with any <code>const</code> declaration, binding <code>x</code> to new value of the same type is not prevented and the registration will not be updated.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/show.jl#L9-L22">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.@more-Tuple{}" href="#MLJBase.@more-Tuple{}"><code>MLJBase.@more</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-julia">@more</code></pre><p>Entered at the REPL, equivalent to <code>show(ans, 100)</code>. Use to get a recursive description of all fields of the last REPL value.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/show.jl#L166-L173">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase._cummulative-Union{Tuple{UnivariateNominal{L,T}}, Tuple{T}, Tuple{L}} where T&lt;:Real where L" href="#MLJBase._cummulative-Union{Tuple{UnivariateNominal{L,T}}, Tuple{T}, Tuple{L}} where T&lt;:Real where L"><code>MLJBase._cummulative</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">_cummulative(d::UnivariateNominal)</code></pre><p>Return the cummulative probability vector <code>[0, ..., 1]</code> for the distribution <code>d</code>, using whatever ordering is used in the dictionary <code>d.prob_given_level</code>. Used only for to implement random sampling from <code>d</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/distributions.jl#L137-L145">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase._rand-Tuple{Any}" href="#MLJBase._rand-Tuple{Any}"><code>MLJBase._rand</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p><em>rand(p</em>cummulative)</p><p>Randomly sample the distribution with discrete support <code>1:n</code> which has cummulative probability vector <code>p_cummulative=[0, ..., 1]</code> (of length <code>n+1</code>). Does not check the first and last elements of <code>p_cummulative</code> but does not use them either. </p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/distributions.jl#L159-L167">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase._recursive_show-Tuple{IO,MLJType,Any,Any}" href="#MLJBase._recursive_show-Tuple{IO,MLJType,Any,Any}"><code>MLJBase._recursive_show</code></a> — <span class="docstring-category">Method</span>.</div><div><div><pre><code class="language-julia">_recursive_show(stream, object, current_depth, depth)</code></pre><p>Generate a table of the field values of the <code>MLJType</code> object, dislaying each value by calling the method <code>_show</code> on it. The behaviour of <code>_show(stream, f)</code> is as follows:</p><ol><li>If <code>f</code> is itself a <code>MLJType</code> object, then its short form is shown</li></ol><p>and <code>_recursive_show</code> generates as separate table for each of its field values (and so on, up to a depth of argument <code>depth</code>).</p><ol><li>Otherwise <code>f</code> is displayed as &quot;(omitted T)&quot; where <code>T = typeof(f)</code>,</li></ol><p>unless <code>istoobig(f)</code> is false (the <code>istoobig</code> fall-back for arbitrary types being <code>true</code>). In the latter case, the long (ie, MIME&quot;plain/text&quot;) form of <code>f</code> is shown. To override this behaviour, overload the <code>_show</code> method for the type in question. </p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/show.jl#L263-L280">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.abbreviated-Tuple{Any}" href="#MLJBase.abbreviated-Tuple{Any}"><code>MLJBase.abbreviated</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>to display abbreviated versions of integers</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/show.jl#L35">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJBase.handle-Tuple{Any}" href="#MLJBase.handle-Tuple{Any}"><code>MLJBase.handle</code></a> — <span class="docstring-category">Method</span>.</div><div><div><p>return abbreviated object id (as string)  or it&#39;s registered handle (as string) if this exists</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJBase.jl/blob/a99b92405b1436b512db6bf1850b46e6b62bb00d/src/show.jl#L41">source</a></section><h3><a class="nav-anchor" id="Index-1" href="#Index-1">Index</a></h3><ul><li><a href="#MLJ.SimpleDeterministicCompositeModel"><code>MLJ.SimpleDeterministicCompositeModel</code></a></li><li><a href="../learning_networks/#MLJ.node"><code>MLJ.node</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.CategoricalDecoder"><code>MLJBase.CategoricalDecoder</code></a></li><li><a href="#MLJBase.StratifiedKFold"><code>MLJBase.StratifiedKFold</code></a></li><li><a href="#MLJBase.SupervisedTask-Tuple{Any,Any}"><code>MLJBase.SupervisedTask</code></a></li><li><a href="../working_with_tasks/#MLJBase.SupervisedTask"><code>MLJBase.SupervisedTask</code></a></li><li><a href="#MLJBase.UnivariateNominal"><code>MLJBase.UnivariateNominal</code></a></li><li><a href="../working_with_tasks/#MLJBase.UnsupervisedTask"><code>MLJBase.UnsupervisedTask</code></a></li><li><a href="#MLJBase.UnsupervisedTask-Tuple{}"><code>MLJBase.UnsupervisedTask</code></a></li><li><a href="#Base.copy"><code>Base.copy</code></a></li><li><a href="#Base.merge!-Tuple{Array{T,1} where T,Array{T,1} where T}"><code>Base.merge!</code></a></li><li><a href="#Base.range-Union{Tuple{D}, Tuple{MLJType,Symbol}} where D"><code>Base.range</code></a></li><li><a href="#MLJ.EnsembleModel-Tuple{}"><code>MLJ.EnsembleModel</code></a></li><li><a href="#MLJ.TunedModel-Tuple{}"><code>MLJ.TunedModel</code></a></li><li><a href="#MLJ.evaluate!-Tuple{Machine}"><code>MLJ.evaluate!</code></a></li><li><a href="#MLJ.flat_keys-Tuple{Pair{Symbol,B} where B}"><code>MLJ.flat_keys</code></a></li><li><a href="#MLJ.get_type-Tuple{Any,Symbol}"><code>MLJ.get_type</code></a></li><li><a href="#MLJ.iterator-Union{Tuple{M}, Tuple{M,NamedTuple}} where M&lt;:Model"><code>MLJ.iterator</code></a></li><li><a href="#MLJ.learning_curve!-Tuple{Machine{#s74} where #s74&lt;:Supervised}"><code>MLJ.learning_curve!</code></a></li><li><a href="../working_with_tasks/#MLJ.localmodels-Tuple{}"><code>MLJ.localmodels</code></a></li><li><a href="../working_with_tasks/#MLJ.models-Tuple{}"><code>MLJ.models</code></a></li><li><a href="#MLJ.rmsp-Tuple{AbstractArray{#s12,1} where #s12&lt;:Real,Any}"><code>MLJ.rmsp</code></a></li><li><a href="#MLJ.scale-Tuple{MLJ.NominalRange}"><code>MLJ.scale</code></a></li><li><a href="../learning_networks/#MLJ.source-Tuple{Any}"><code>MLJ.source</code></a></li><li><a href="#MLJ.sources-Tuple{MLJ.Source}"><code>MLJ.sources</code></a></li><li><a href="../learning_networks/#MLJ.sources"><code>MLJ.sources</code></a></li><li><a href="#MLJ.unwind-Tuple"><code>MLJ.unwind</code></a></li><li><a href="#MLJBase._cummulative-Union{Tuple{UnivariateNominal{L,T}}, Tuple{T}, Tuple{L}} where T&lt;:Real where L"><code>MLJBase._cummulative</code></a></li><li><a href="#MLJBase._rand-Tuple{Any}"><code>MLJBase._rand</code></a></li><li><a href="#MLJBase._recursive_show-Tuple{IO,MLJType,Any,Any}"><code>MLJBase._recursive_show</code></a></li><li><a href="#MLJBase.abbreviated-Tuple{Any}"><code>MLJBase.abbreviated</code></a></li><li><a href="../scientific_data_types/#MLJBase.column_scitypes_as_tuple"><code>MLJBase.column_scitypes_as_tuple</code></a></li><li><a href="#MLJBase.column_scitypes_as_tuple-Tuple{Any}"><code>MLJBase.column_scitypes_as_tuple</code></a></li><li><a href="#MLJBase.container_type-Tuple{Any}"><code>MLJBase.container_type</code></a></li><li><a href="#MLJBase.datanow-Tuple{}"><code>MLJBase.datanow</code></a></li><li><a href="#MLJBase.fitresult_type-Tuple{Type{#s37} where #s37&lt;:Supervised}"><code>MLJBase.fitresult_type</code></a></li><li><a href="#MLJBase.handle-Tuple{Any}"><code>MLJBase.handle</code></a></li><li><a href="#MLJBase.info-Tuple{String}"><code>MLJBase.info</code></a></li><li><a href="#MLJBase.load_ames-Tuple{}"><code>MLJBase.load_ames</code></a></li><li><a href="#MLJBase.load_boston-Tuple{}"><code>MLJBase.load_boston</code></a></li><li><a href="#MLJBase.load_crabs-Tuple{}"><code>MLJBase.load_crabs</code></a></li><li><a href="#MLJBase.load_iris-Tuple{}"><code>MLJBase.load_iris</code></a></li><li><a href="#MLJBase.load_reduced_ames-Tuple{}"><code>MLJBase.load_reduced_ames</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.matrix"><code>MLJBase.matrix</code></a></li><li><a href="#MLJBase.matrix-Tuple{Any}"><code>MLJBase.matrix</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.nrows"><code>MLJBase.nrows</code></a></li><li><a href="#MLJBase.nrows-Tuple{Any}"><code>MLJBase.nrows</code></a></li><li><a href="#MLJBase.params-Tuple{Any}"><code>MLJBase.params</code></a></li><li><a href="#MLJBase.partition-Tuple{AbstractArray{Int64,1},Vararg{Any,N} where N}"><code>MLJBase.partition</code></a></li><li><a href="#MLJBase.schema-Tuple{Any}"><code>MLJBase.schema</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.schema"><code>MLJBase.schema</code></a></li><li><a href="#MLJBase.scitype-Tuple{Any}"><code>MLJBase.scitype</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.select"><code>MLJBase.select</code></a></li><li><a href="#MLJBase.select-Tuple{Any,Any,Any}"><code>MLJBase.select</code></a></li><li><a href="#MLJBase.selectcols-Tuple{Any,Any}"><code>MLJBase.selectcols</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.selectcols"><code>MLJBase.selectcols</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.selectrows"><code>MLJBase.selectrows</code></a></li><li><a href="#MLJBase.selectrows-Tuple{Any,Any}"><code>MLJBase.selectrows</code></a></li><li><a href="../adding_models_for_general_use/#MLJBase.table"><code>MLJBase.table</code></a></li><li><a href="#MLJBase.table-Tuple{NamedTuple}"><code>MLJBase.table</code></a></li><li><a href="../scientific_data_types/#MLJBase.union_scitypes"><code>MLJBase.union_scitypes</code></a></li><li><a href="#MLJBase.union_scitypes-Tuple{Any}"><code>MLJBase.union_scitypes</code></a></li><li><a href="#StatsBase.fit!-Tuple{MLJ.AbstractMachine}"><code>StatsBase.fit!</code></a></li><li><a href="../learning_networks/#StatsBase.fit!-Tuple{Node}"><code>StatsBase.fit!</code></a></li><li><a href="#MLJ.@curve-Tuple{Any,Any,Any}"><code>MLJ.@curve</code></a></li><li><a href="#MLJBase.@constant-Tuple{Any}"><code>MLJBase.@constant</code></a></li><li><a href="#MLJBase.@more-Tuple{}"><code>MLJBase.@more</code></a></li></ul><footer><hr/><a class="previous" href="../glossary/"><span class="direction">Previous</span><span class="title">Glossary</span></a><a class="next" href="../frequently_asked_questions/"><span class="direction">Next</span><span class="title">FAQ</span></a></footer></article></body></html>
