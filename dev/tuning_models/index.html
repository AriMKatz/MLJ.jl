<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tuning models · MLJ</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MLJ</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Getting Started</a></li><li><a class="toctext" href="../evaluating_model_performance/">Evaluating model performance</a></li><li><a class="toctext" href="../measures/">Measures</a></li><li class="current"><a class="toctext" href>Tuning models</a><ul class="internal"></ul></li><li><a class="toctext" href="../built_in_transformers/">Built-in Transformers</a></li><li><a class="toctext" href="../learning_networks/">Learning Networks</a></li><li><a class="toctext" href="../simple_user_defined_models/">Simple User Defined Models</a></li><li><a class="toctext" href="../adding_models_for_general_use/">Adding Models for General Use</a></li><li><a class="toctext" href="../working_with_tasks/">Working with Tasks</a></li><li><a class="toctext" href="../benchmarking/">Benchmarking</a></li><li><a class="toctext" href="../internals/">Internals</a></li><li><a class="toctext" href="../glossary/">Glossary</a></li><li><a class="toctext" href="../api/">API</a></li><li><a class="toctext" href="../mlj_cheatsheet/">MLJ Cheatsheet</a></li><li><a class="toctext" href="../NEWS/">MLJ News</a></li><li><a class="toctext" href="../frequently_asked_questions/">FAQ</a></li><li><a class="toctext" href="../julia_blogpost/">Julia BlogPost</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Tuning models</a></li></ul><a class="edit-page" href="https://github.com/alan-turing-institute/MLJ.jl/blob/master/docs/src/tuning_models.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Tuning models</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Tuning-models-1" href="#Tuning-models-1">Tuning models</a></h1><h3><a class="nav-anchor" id="API-1" href="#API-1">API</a></h3><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.range" href="#Base.range"><code>Base.range</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">r = range(model, :hyper; values=nothing)</code></pre><p>Defines a <code>NominalRange</code> object for a field <code>hyper</code> of <code>model</code>, assuming the field is a not a subtype of <code>Real</code>. Note that <code>r</code> is not directly iterable but <code>iterator(r)</code> iterates over <code>values</code>.</p><p>A nested hyperparameter is specified using dot notation. For example, <code>:(atom.max_depth)</code> specifies the <code>:max_depth</code> hyperparameter of the hyperparameter <code>:atom</code> of <code>model</code>.</p><pre><code class="language-none">r = range(model, :hyper; upper=nothing, lower=nothing, scale=:linear)</code></pre><p>Defines a <code>NumericRange</code> object for a <code>Real</code> field <code>hyper</code> of <code>model</code>. Note that <code>r</code> is not directly iteratable but <code>iterator(r, n)</code> iterates over <code>n</code> values between <code>lower</code> and <code>upper</code> values, according to the specified <code>scale</code>. The supported scales are <code>:linear, :log, :log10, :log2</code>. Values for <code>Integer</code> types are rounded (with duplicate values removed, resulting in possibly less than <code>n</code> values).</p><p>Alternatively, if a function <code>f</code> is provided as <code>scale</code>, then <code>iterator(r, n)</code> iterates over the values <code>[f(x1), f(x2), ... , f(xn)]</code>, where <code>x1, x2, ..., xn</code> are linearly spaced between <code>lower</code> and <code>upper</code>.</p><p>See also: <a href="@ref"><code>iterator</code></a>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/96c94588ca06ea5cb4855e4290c97d7d4208491d/src/parameters.jl#L69-L96">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLJ.TunedModel" href="#MLJ.TunedModel"><code>MLJ.TunedModel</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">tuned_model = TunedModel(; model=nothing,
                         tuning=Grid(),
                         resampling=Holdout(),
                         measure=nothing,
                         weights=nothing,
                         operation=predict,
                         ranges=ParamRange[],
                         full_report=true)</code></pre><p>Construct a model wrapper for hyperparameter optimization of a supervised learner.</p><p>Calling <code>fit!(mach)</code> on a machine <code>mach=machine(tuned_model, X, y)</code> or <code>mach=machine(tuned_model, task)</code> will: </p><ul><li><p>Instigate a search, over clones of <code>model</code> with the hyperparameter mutations specified by <code>ranges</code>, for a model optimizing the specified <code>measure</code>, using performance evaluations carried out using the specified <code>tuning</code> strategy and <code>resampling</code> strategy.</p></li><li><p>Fit a machine, <code>mach_optimal = fitted_params(mach).best_model</code>, wrapping the optimal <code>model</code> object in <em>all</em> the provided data <code>X, y</code> (or in <code>task</code>). Calling <code>predict(mach, Xnew)</code> then returns predictions on <code>Xnew</code> of the machine <code>mach_optimal</code>.</p></li></ul><p>If a custom measure <code>measure</code> is used, and the measure is a score, rather than a loss, be sure to check that <code>MLJ.orientation(measure) == :score</code> to ensure maximization of the measure, rather than minimization. Overide an incorrect value with <code>MLJ.orientation(::typeof(measure)) = :score</code>. </p><p>If <code>measure</code> supports sample weights (<code>MLJ.supports_weights(measure) == true</code>) then these can be passed to the measure as <code>weights</code>.</p><p>In the case of two-parameter tuning, a Plots.jl plot of performance estimates is returned by <code>plot(mach)</code> or <code>heatmap(mach)</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/alan-turing-institute/MLJ.jl/blob/96c94588ca06ea5cb4855e4290c97d7d4208491d/src/tuning.jl#L57-L95">source</a></section><footer><hr/><a class="previous" href="../measures/"><span class="direction">Previous</span><span class="title">Measures</span></a><a class="next" href="../built_in_transformers/"><span class="direction">Next</span><span class="title">Built-in Transformers</span></a></footer></article></body></html>
